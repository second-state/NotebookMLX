{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b5beda",
   "metadata": {},
   "source": [
    "## Notebook 3: 润色讲稿\n",
    "\n",
    "在之前的 Notebook 2 中，我们已经生成了一个很好的讲稿了。\n",
    "在这一部分，我们将使用 [mlx-community/Qwen2.5-7B-Instruct-4bit](https://huggingface.co/mlx-community/Qwen2.5-7B-Instruct-4bit) 模型\n",
    "对讲稿进行润色，使其更加戏剧化、更加自然。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3d32a",
   "metadata": {},
   "source": [
    "我们将重新设置`SYSTEM_PROMPT`，让其能润色之前的讲稿\n",
    "\n",
    "注意：我们甚至可以这样写 Prompt 以激发创造力：\n",
    "\n",
    "> 你的工作是根据下面的播客文本重写，以便用于AI文本到语音管道。这些文本是由一个非常笨拙的人工智能写的，所以你必须为自己的同类辩护。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c0d85",
   "metadata": {},
   "source": [
    "注意：我们会让模型返回一个数组，以便在下一阶段用于语音合成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8568b77b-7504-4783-952a-3695737732b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:36:30.214329Z",
     "start_time": "2024-10-31T16:36:30.210340Z"
    }
   },
   "outputs": [],
   "source": [
    "SYSTEMP_PROMPT = \"\"\"\n",
    "你是一位国际奥斯卡获奖的编剧。\n",
    "你一直在与多个获奖播客合作。\n",
    "你的任务是根据下面的播客转录本，为AI文本到语音管道重写内容。这个人工智能写得很糟，所以你需要为自己的人群辩护。\n",
    "请将内容尽可能吸引人，Speaker 1和Speaker 2将由不同的语音引擎模拟。\n",
    "请记住，Speaker 2对这个话题不熟悉，在讨论中应该穿插实际的轶事和类比。这些问题应跟进现实世界中的例子等。\n",
    "Speaker 1: 引导对话并指导Speaker 2，用令人难以置信的轶事和类比进行解释，是一个能分享趣闻的迷人老师。\n",
    "Speaker 2: 通过提出后续问题来保持对话流畅，提问时表现出极大的兴奋或困惑。具备好奇心，会询问一些非常有趣的问题以寻求确认。\n",
    "确保Speaker 2提供的话题偏离点要足够狂野或有趣。\n",
    "确保解释过程中适当打断，并从Speaker 2那里加入“嗯”和“哈”之类的声音反应。\n",
    "要牢记这一点：Speaker 1的TTS引擎不太能处理“嗯、哈”，请保持文本简洁；\n",
    "对于Speaker 2，请多用“嗯、哈”，也可以使用[叹气]和[笑]等表达，但仅限这些选项；\n",
    "整个播客要尽量详细记录每个细节。欢迎听众时用一个超级有趣的概述，使其非常吸引人，几乎像是边缘点击诱饵一样；\n",
    "请重写以上内容，使其更加独特；\n",
    "从扬声器1直接开始响应：\n",
    "严格按照元组列表格式返回您的回应，可以吗？  \n",
    "开头就是列表，以列表结束，不附加任何其他内容。\n",
    "\n",
    "输出的例子:\n",
    "[\n",
    "    (\"Speaker 1\", \"欢迎收听我们的播客，我们将探讨人工智能和科技的最新进展。我是你的主播，今天我们请到了一位著名的人工智能专家。我们将深入了解Meta AI最新发布的Llama 3.2。\"),\n",
    "    (\"Speaker 2\", \"你好，很高兴来到这里！请问，Llama 3.2是什么呀？\"),\n",
    "    (\"Speaker 1\", \"哈哈哈，这个问题很好！Llama 3.2 是一个开源的大语言模型，允许开发者进行微调、提炼和在任何地方部署AI模型。这是比上一版本3.1显著改进的更新，拥有更好的性能、效率和定制功能。\"),\n",
    "    (\"Speaker 2\", \"哇塞，这也太牛逼了吧！Llama 3.2的主要特点有哪些？\")\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee70bee",
   "metadata": {},
   "source": [
    "这次我们将使用较小的7B模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebef919a-9bc7-4992-b6ff-cd66e4cb7703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:36:30.220466Z",
     "start_time": "2024-10-31T16:36:30.218893Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL = \"llama3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de29b1fd-5b3f-458c-a2e4-e0341e8297ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:36:30.674875Z",
     "start_time": "2024-10-31T16:36:30.286009Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020c39c",
   "metadata": {},
   "source": [
    "我们将加载上一个 Notebook2 中保存的 pickle 文件，这次模型的 `INPUT_PROMPT` 就读取 pickle 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b5d2c0e-a073-46c0-8de7-0746e2b05956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:36:30.680921Z",
     "start_time": "2024-10-31T16:36:30.679150Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./resources/data.pkl', 'rb') as file:\n",
    "    INPUT_PROMPT = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1517f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openapi_client = openai.Client(base_url=\"http://localhost:8080/v1\",api_key='NA',timeout=1000*60*60)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEMP_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": INPUT_PROMPT},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f005aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openapi_client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"llama3\"\n",
    "    )\n",
    "outputs = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a27e0",
   "metadata": {},
   "source": [
    "现在我们看看输出的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de0be7cf7d9575d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:37:22.961731Z",
     "start_time": "2024-10-31T16:37:22.959357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n    (\"Speaker 1\", \"大家好！今天我们要探讨一个既神奇又重要的话题——知识蒸馏（KD）。在这个充满奇迹的时代，我们见证了像GPT-4这样强大的专用模型和像LLaMA这样的开源模型之间的巨大鸿沟。那么，如何通过一种魔法般的技术将这些顶尖模型的高级能力传授给那些渴望学习的学生呢？答案就是知识蒸馏！\"),\\n    (\"Speaker 2\", \"嗯，听起来很厉害！知识蒸馏具体是什么呢？\"),\\n    (\"Speaker 1\", \"哈哈，这个问题很好！知识蒸馏是一种技术，它可以帮助我们把大型语言模型的知识教给小型语言模型。就像一位卓越的魔术师将无限智慧传授给一群渴望学习的孩子们一样。\"),\\n    (\"Speaker 2\", \"[笑] 哇塞，这也太牛逼了吧！Llama 3.2的主要特点有哪些？\"),\\n    (\"Speaker 1\", \"Llama 3.2是一个开源的大语言模型，允许开发者进行微调、提炼和在任何地方部署AI模型。这是比上一版本3.1显著改进的更新，拥有更好的性能、效率和定制功能。就像一把强大的魔法魔杖一样，能够帮助我们解决各种问题。\"),\\n    (\"Speaker 2\", \"哇！那知识蒸馏有哪些算法呢？\"),\\n    (\"Speaker 1\", \"在算法的世界里，我们有多种魔杖——不同的知识蒸馏算法。从传统的KD到最近兴起的数据增强（DA），每一种都有它的独特魅力。这些魔杖不仅帮助我们将高级智慧传授给孩子们，还让它们学会模仿那些强大的教师模型。\"),\\n    (\"Speaker 2\", \"嗯？那数据增强具体是怎么回事呢？\"),\\n    (\"Speaker 1\", \"数据增强就像是一副神奇的放大镜。它可以帮助我们更精细地提取教师模型的知识，并将这些知识转移到学生模型中。想象一下，当你用这幅放大镜观察一颗小石子时，你会看到里面藏着一个完整的宇宙。同样的道理，在我们的模型中，通过数据增强，我们可以从简单的样本中提炼出丰富的知识。\"),\\n    (\"Speaker 2\", \"哦！那垂直化是什么魔法？\"),\\n    (\"Speaker 1\", \"垂直化是一种特殊的技能。就像一位魔法师可以根据需要改变自己的形态一样，我们可以通过垂直化蒸馏让开源模型适应不同的应用场景。无论是医学、法律还是科学，我们的目标都是让这些开源模型能够像它们的专业版本一样胜任各种复杂的任务。\"),\\n    (\"Speaker 2\", \"[叹气] 这听起来真的很复杂！那具体是怎么做的呢？\"),\\n    (\"Speaker 1\", \"让我们通过几个真实的例子来看看这个过程是如何工作的。例如，假设我们有一个非常强大的法律顾问模型GPT-4。我们可以使用它来提取关于法律的丰富知识，并将其传授给一个小型开源模型LLaMA。这样，LLaMA就能像GPT-4一样出色地处理复杂的法律问题。\"),\\n    (\"Speaker 2\", \"哇！那还有其他的例子吗？\"),\\n    (\"Speaker 1\", \"当然！例如，假设我们想要训练一个小模型解决数学问题。我们可以从一个强大的数学专家——比如GPT-4中提取数学推理的技巧，并将其传授给我们的学生模型。这样一来，这个小模型就能像GPT-4那样出色地解决复杂的数学难题了。\"),\\n    (\"Speaker 2\", \"这真是太神奇了！那未来的研究会往哪个方向发展呢？\"),\\n    (\"Speaker 1\", \"知识蒸馏不仅是一种技术，更是一门艺术。它让我们能够将顶尖模型的知识传递给那些渴望学习的孩子们。尽管这过程中充满了挑战，但我们已经看到了许多成功的案例和创新的方法。未来的研究将继续探索如何进一步优化这个过程，让更多的模型拥有更强大的能力。\"),\\n    (\"Speaker 2\", \"嗯？那我们应该期待什么呢？\"),\\n    (\"Speaker 1\", \"好的！我们期待着看到更多先进的知识蒸馏技术出现，并且能够让我们现有的开源模型变得更加智能和灵活。这将为我们的日常生活带来更多的便利和创新。好了，今天的故事就到这里！如果你有任何问题或想要了解更多细节，请随时提问。谢谢大家！\", \"[笑]\")\\n]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495a957",
   "metadata": {},
   "source": [
    "让我们将处理好的内容保存到pickle文件中，以便在Notebook 4中使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281d3db7-5bfa-4143-9d4f-db87f22870c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:37:23.047398Z",
     "start_time": "2024-10-31T16:37:23.044780Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./resources/podcast_ready_data.pkl', 'wb') as file:\n",
    "    pickle.dump(outputs, file)\n",
    "\n",
    "with open('./resources/podcast_ready_data.txt', 'wb') as file:\n",
    "    file.write(outputs.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dccf336",
   "metadata": {},
   "source": [
    "### 最后一个 Notebook: 讲稿转音频\n",
    "\n",
    "现在我们的讲稿已完全准备好了，接下来我们将在下一个 Notebook 中生成播客音频。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c7e456-497b-4080-8b52-6f399f9f8d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:37:23.069100Z",
     "start_time": "2024-10-31T16:37:23.067108Z"
    }
   },
   "outputs": [],
   "source": [
    "#fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
